{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6df9ec3d-ed34-4358-ac55-af209f31db87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d484acdf-3a86-4e88-8cb1-035f41f3a2da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.orders: 99,441 records\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Read from Bronze\n",
    "bronze_orders = spark.table(\"ecommerce.bronze.raw_orders\")\n",
    "\n",
    "# Transform\n",
    "silver_orders = (\n",
    "    bronze_orders\n",
    "    \n",
    "    # ── Remove duplicates ───────────────────────────────────────\n",
    "    .dropDuplicates([\"order_id\"])\n",
    "    \n",
    "    # ── Filter out records with no order_id ─────────────────────\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "    \n",
    "    # ── Standardize status to UPPERCASE ─────────────────────────\n",
    "    .withColumn(\"order_status\", F.upper(F.trim(F.col(\"order_status\"))))\n",
    "    \n",
    "    # ── Cast date strings to TIMESTAMP ──────────────────────────\n",
    "    .withColumn(\"order_purchase_timestamp\",\n",
    "        F.to_timestamp(\"order_purchase_timestamp\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    .withColumn(\"order_approved_at\",\n",
    "        F.to_timestamp(\"order_approved_at\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    .withColumn(\"order_delivered_carrier_date\",\n",
    "        F.to_timestamp(\"order_delivered_carrier_date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    .withColumn(\"order_delivered_customer_date\",\n",
    "        F.to_timestamp(\"order_delivered_customer_date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    .withColumn(\"order_estimated_delivery_date\",\n",
    "        F.to_timestamp(\"order_estimated_delivery_date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    \n",
    "    # ── Add delivery delay column (business insight) ─────────────\n",
    "    .withColumn(\"delivery_delay_days\",\n",
    "        F.when(\n",
    "            F.col(\"order_delivered_customer_date\").isNotNull(),\n",
    "            F.datediff(\n",
    "                F.col(\"order_delivered_customer_date\"),\n",
    "                F.col(\"order_estimated_delivery_date\")\n",
    "            )\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # ── Add updated_at timestamp ─────────────────────────────────\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "    \n",
    "    # ── Drop Bronze metadata columns ─────────────────────────────\n",
    "    .drop(\"_ingestion_time\", \"_source_file\")\n",
    ")\n",
    "\n",
    "# Write to Silver\n",
    "(silver_orders.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.orders\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.orders\").count()\n",
    "print(f\"silver.orders: {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "214d5cb9-53b9-4a64-a625-64ebe7546a4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d96a160c-5d11-4ffa-81c5-3ffae341b4c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.customers: 99,441 records\n"
     ]
    }
   ],
   "source": [
    "bronze_customers = spark.table(\"ecommerce.bronze.raw_customers\")\n",
    "\n",
    "silver_customers = (\n",
    "    bronze_customers\n",
    "\n",
    "    # ── Remove duplicates ───────────────────────────────────────\n",
    "    .dropDuplicates([\"customer_id\"])\n",
    "\n",
    "    # ── Filter nulls ────────────────────────────────────────────\n",
    "    .filter(F.col(\"customer_id\").isNotNull())\n",
    "\n",
    "    # ── Standardize city and state ───────────────────────────────\n",
    "    .withColumn(\"customer_city\",\n",
    "        F.initcap(F.trim(F.col(\"customer_city\"))))   # \"sao paulo\" → \"Sao Paulo\"\n",
    "    .withColumn(\"customer_state\",\n",
    "        F.upper(F.trim(F.col(\"customer_state\"))))    # \"sp\" → \"SP\"\n",
    "\n",
    "    # ── Cast zip code to integer ─────────────────────────────────\n",
    "    .withColumn(\"customer_zip_code_prefix\",\n",
    "        F.col(\"customer_zip_code_prefix\").cast(\"integer\"))\n",
    "\n",
    "    # ── Add updated_at ───────────────────────────────────────────\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "\n",
    "    # ── Drop Bronze metadata ─────────────────────────────────────\n",
    "    .drop(\"_ingestion_time\", \"_source_file\")\n",
    ")\n",
    "\n",
    "(silver_customers.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.customers\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.customers\").count()\n",
    "print(f\"silver.customers: {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "930c295f-db66-42b2-8082-3640456ed276",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e42b3301-aa28-450f-b5cc-16893242ed46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.products: 32,951 records\n"
     ]
    }
   ],
   "source": [
    "bronze_products = spark.table(\"ecommerce.bronze.raw_products\")\n",
    "\n",
    "silver_products = (\n",
    "    bronze_products\n",
    "\n",
    "    # ── Remove duplicates ───────────────────────────────────────\n",
    "    .dropDuplicates([\"product_id\"])\n",
    "\n",
    "    # ── Filter nulls ────────────────────────────────────────────\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "\n",
    "    # ── Standardize category name ────────────────────────────────\n",
    "    .withColumn(\"product_category_name\",\n",
    "        F.initcap(F.trim(\n",
    "            F.regexp_replace(\"product_category_name\", \"_\", \" \")\n",
    "        ))\n",
    "    )   # \"telefonia_fixa\" → \"Telefonia Fixa\"\n",
    "\n",
    "    # ── Cast numeric columns ─────────────────────────────────────\n",
    "    .withColumn(\"product_name_lenght\",\n",
    "        F.col(\"product_name_lenght\").cast(\"integer\"))\n",
    "    .withColumn(\"product_description_lenght\",\n",
    "        F.col(\"product_description_lenght\").cast(\"integer\"))\n",
    "    .withColumn(\"product_photos_qty\",\n",
    "        F.col(\"product_photos_qty\").cast(\"integer\"))\n",
    "    .withColumn(\"product_weight_g\",\n",
    "        F.col(\"product_weight_g\").cast(\"double\"))\n",
    "    .withColumn(\"product_length_cm\",\n",
    "        F.col(\"product_length_cm\").cast(\"double\"))\n",
    "    .withColumn(\"product_height_cm\",\n",
    "        F.col(\"product_height_cm\").cast(\"double\"))\n",
    "    .withColumn(\"product_width_cm\",\n",
    "        F.col(\"product_width_cm\").cast(\"double\"))\n",
    "\n",
    "    # ── Calculate product volume (business insight) ───────────────\n",
    "    .withColumn(\"product_volume_cm3\",\n",
    "        F.col(\"product_length_cm\") *\n",
    "        F.col(\"product_height_cm\") *\n",
    "        F.col(\"product_width_cm\")\n",
    "    )\n",
    "\n",
    "    # ── Add updated_at ───────────────────────────────────────────\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "\n",
    "    # ── Drop Bronze metadata ─────────────────────────────────────\n",
    "    .drop(\"_ingestion_time\", \"_source_file\")\n",
    ")\n",
    "\n",
    "(silver_products.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.products\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.products\").count()\n",
    "print(f\"silver.products: {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cc841ad-fd66-4af9-8874-5a678cd9ac0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Order Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a59a5dfd-d26e-4ca1-b0fd-8bca125cd00e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.order_items: 112,650 records\n"
     ]
    }
   ],
   "source": [
    "bronze_items = spark.table(\"ecommerce.bronze.raw_order_items\")\n",
    "\n",
    "silver_order_items = (\n",
    "    bronze_items\n",
    "\n",
    "    # ── Remove duplicates ───────────────────────────────────────\n",
    "    .dropDuplicates([\"order_id\", \"order_item_id\"])\n",
    "\n",
    "    # ── Filter nulls on key columns ──────────────────────────────\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "\n",
    "    # ── Cast numeric columns ─────────────────────────────────────\n",
    "    .withColumn(\"order_item_id\",\n",
    "        F.col(\"order_item_id\").cast(\"integer\"))\n",
    "    .withColumn(\"price\",\n",
    "        F.col(\"price\").cast(\"double\"))\n",
    "    .withColumn(\"freight_value\",\n",
    "        F.col(\"freight_value\").cast(\"double\"))\n",
    "\n",
    "    # ── Cast date ────────────────────────────────────────────────\n",
    "    .withColumn(\"shipping_limit_date\",\n",
    "        F.to_timestamp(\"shipping_limit_date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "    # ── Calculate line total (price + freight) ────────────────────\n",
    "    .withColumn(\"line_total\",\n",
    "        F.round(F.col(\"price\") + F.col(\"freight_value\"), 2))\n",
    "\n",
    "    # ── Add updated_at ───────────────────────────────────────────\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "\n",
    "    # ── Drop Bronze metadata ─────────────────────────────────────\n",
    "    .drop(\"_ingestion_time\", \"_source_file\")\n",
    ")\n",
    "\n",
    "(silver_order_items.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.order_items\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.order_items\").count()\n",
    "print(f\"silver.order_items: {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73e29daa-710b-46ec-9bb3-5054a0b27725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05c1d1c0-b9c4-49d8-a912-6451e9966dde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.payments: 103,883 records\n"
     ]
    }
   ],
   "source": [
    "bronze_payments = spark.table(\"ecommerce.bronze.raw_payments\")\n",
    "\n",
    "silver_payments = (\n",
    "    bronze_payments\n",
    "\n",
    "    # ── Remove duplicates ───────────────────────────────────────\n",
    "    .dropDuplicates([\"order_id\", \"payment_sequential\"])\n",
    "\n",
    "    # ── Filter nulls ────────────────────────────────────────────\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "\n",
    "    # ── Filter out not_defined payment types ─────────────────────\n",
    "    .filter(F.col(\"payment_type\") != \"not_defined\")\n",
    "\n",
    "    # ── Standardize payment type ─────────────────────────────────\n",
    "    .withColumn(\"payment_type\",\n",
    "        F.upper(F.trim(F.col(\"payment_type\"))))\n",
    "\n",
    "    # ── Cast numeric columns ─────────────────────────────────────\n",
    "    .withColumn(\"payment_sequential\",\n",
    "        F.col(\"payment_sequential\").cast(\"integer\"))\n",
    "    .withColumn(\"payment_installments\",\n",
    "        F.col(\"payment_installments\").cast(\"integer\"))\n",
    "    .withColumn(\"payment_value\",\n",
    "        F.col(\"payment_value\").cast(\"double\"))\n",
    "\n",
    "    # ── Add updated_at ───────────────────────────────────────────\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "\n",
    "    # ── Drop Bronze metadata ─────────────────────────────────────\n",
    "    .drop(\"_ingestion_time\", \"_source_file\")\n",
    ")\n",
    "\n",
    "(silver_payments.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.payments\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.payments\").count()\n",
    "print(f\"silver.payments: {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d259ac9c-7a2f-4378-870b-1056799ff4d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4355b1e1-26e5-4c42-8f1e-79d884ed3aef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.reviews: 98,410 records\n"
     ]
    }
   ],
   "source": [
    "bronze_reviews = spark.table(\"ecommerce.bronze.raw_reviews\")\n",
    "\n",
    "silver_reviews = (\n",
    "    bronze_reviews\n",
    "\n",
    "    # ── Remove duplicates ───────────────────────────────────────\n",
    "    .dropDuplicates([\"review_id\"])\n",
    "\n",
    "    # ── Filter nulls ────────────────────────────────────────────\n",
    "    .filter(F.col(\"review_id\").isNotNull())\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "\n",
    "    # ── Cast review score to integer ─────────────────────────────\n",
    "    .withColumn(\"review_score\",\n",
    "        F.col(\"review_score\").cast(\"integer\"))\n",
    "\n",
    "    # ── Cast dates ───────────────────────────────────────────────\n",
    "    .withColumn(\"review_creation_date\",\n",
    "        F.to_timestamp(\"review_creation_date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    .withColumn(\"review_answer_timestamp\",\n",
    "        F.to_timestamp(\"review_answer_timestamp\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "    # ── Clean comment text ───────────────────────────────────────\n",
    "    .withColumn(\"review_comment_title\",\n",
    "        F.when(F.col(\"review_comment_title\").isNull(), \"No Title\")\n",
    "         .otherwise(F.trim(F.col(\"review_comment_title\"))))\n",
    "    .withColumn(\"review_comment_message\",\n",
    "        F.when(F.col(\"review_comment_message\").isNull(), \"No Comment\")\n",
    "         .otherwise(F.trim(F.col(\"review_comment_message\"))))\n",
    "\n",
    "    # ── Add sentiment label based on score ───────────────────────\n",
    "    .withColumn(\"sentiment\",\n",
    "        F.when(F.col(\"review_score\") >= 4, \"POSITIVE\")\n",
    "         .when(F.col(\"review_score\") == 3, \"NEUTRAL\")\n",
    "         .otherwise(\"NEGATIVE\")\n",
    "    )\n",
    "\n",
    "    # ── Add updated_at ───────────────────────────────────────────\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "\n",
    "    # ── Drop Bronze metadata ─────────────────────────────────────\n",
    "    .drop(\"_ingestion_time\", \"_source_file\")\n",
    ")\n",
    "\n",
    "(silver_reviews.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.reviews\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.reviews\").count()\n",
    "print(f\"silver.reviews: {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a26d9158-7881-48b4-9a8b-b96ac4c21254",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b9ddcb2-6334-4599-837c-d0be0df3870e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver.sellers: 3,095 records\n"
     ]
    }
   ],
   "source": [
    "bronze_sellers = spark.table(\"ecommerce.bronze.raw_sellers\")\n",
    "\n",
    "silver_sellers = (\n",
    "    bronze_sellers\n",
    "\n",
    "    # ── Remove duplicates ───────────────────────────────────────\n",
    "    .dropDuplicates([\"seller_id\"])\n",
    "\n",
    "    # ── Filter nulls ────────────────────────────────────────────\n",
    "    .filter(F.col(\"seller_id\").isNotNull())\n",
    "\n",
    "    # ── Standardize city and state ───────────────────────────────\n",
    "    .withColumn(\"seller_city\",\n",
    "        F.initcap(F.trim(F.col(\"seller_city\"))))\n",
    "    .withColumn(\"seller_state\",\n",
    "        F.upper(F.trim(F.col(\"seller_state\"))))\n",
    "\n",
    "    # ── Cast zip code ────────────────────────────────────────────\n",
    "    .withColumn(\"seller_zip_code_prefix\",\n",
    "        F.col(\"seller_zip_code_prefix\").cast(\"integer\"))\n",
    "\n",
    "    # ── Add updated_at ───────────────────────────────────────────\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "\n",
    "    # ── Drop Bronze metadata ─────────────────────────────────────\n",
    "    .drop(\"_ingestion_time\", \"_source_file\")\n",
    ")\n",
    "\n",
    "(silver_sellers.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.sellers\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.sellers\").count()\n",
    "print(f\"silver.sellers: {count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "714c9da0-f397-425d-8cb9-c1ad1333030a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\nSILVER LAYER — FINAL VERIFICATION\n=======================================================\norders                   99,441 records\ncustomers                99,441 records\nproducts                 32,951 records\norder_items             112,650 records\npayments                103,883 records\nreviews                  98,410 records\nsellers                   3,095 records\n---------------------------------------------\nTOTAL                   549,871 records\n\nSample silver.orders:\n+--------------------+------------+------------------------+-------------------+\n|            order_id|order_status|order_purchase_timestamp|delivery_delay_days|\n+--------------------+------------+------------------------+-------------------+\n|f373335aac9a659de...|     SHIPPED|     2018-03-17 15:32:31|               NULL|\n|118045506e1c1dda0...|   DELIVERED|     2018-03-08 19:06:05|                  7|\n|cc66dee6fbc18bb79...|   DELIVERED|     2018-04-12 14:37:29|                -17|\n|f44cb69655f8e4d13...|   DELIVERED|     2018-07-13 22:22:57|                 -6|\n|edcc6b79e8394346b...|   DELIVERED|     2018-04-29 16:03:47|                -14|\n+--------------------+------------+------------------------+-------------------+\nonly showing top 5 rows\nReview sentiment distribution:\n+---------+-----+\n|sentiment|count|\n+---------+-----+\n| POSITIVE|75917|\n| NEGATIVE|14396|\n|  NEUTRAL| 8097|\n+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"SILVER LAYER — FINAL VERIFICATION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "tables = {\n",
    "    \"orders\":      \"ecommerce.silver.orders\",\n",
    "    \"customers\":   \"ecommerce.silver.customers\",\n",
    "    \"products\":    \"ecommerce.silver.products\",\n",
    "    \"order_items\": \"ecommerce.silver.order_items\",\n",
    "    \"payments\":    \"ecommerce.silver.payments\",\n",
    "    \"reviews\":     \"ecommerce.silver.reviews\",\n",
    "    \"sellers\":     \"ecommerce.silver.sellers\",\n",
    "}\n",
    "\n",
    "total = 0\n",
    "for name, table in tables.items():\n",
    "    count = spark.table(table).count()\n",
    "    total += count\n",
    "    print(f\"{name:<20} {count:>10,} records\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'TOTAL':<20} {total:>10,} records\")\n",
    "\n",
    "# ── Show sample silver orders ────────────────────────────────────\n",
    "print(\"\\nSample silver.orders:\")\n",
    "spark.table(\"ecommerce.silver.orders\") \\\n",
    "    .select(\"order_id\", \"order_status\",\n",
    "            \"order_purchase_timestamp\",\n",
    "            \"delivery_delay_days\") \\\n",
    "    .show(5)\n",
    "\n",
    "# ── Show sentiment distribution ──────────────────────────────────\n",
    "print(\"Review sentiment distribution:\")\n",
    "spark.table(\"ecommerce.silver.reviews\") \\\n",
    "    .groupBy(\"sentiment\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_silver_transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}