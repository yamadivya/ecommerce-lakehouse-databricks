{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcea7240-b917-4d66-97f6-8f758265dafd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create the SCD Type 2 Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21a60990-440d-4f02-889b-8d974cb347c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers_scd table created!\n+------------------------+---------+-------+\n|col_name                |data_type|comment|\n+------------------------+---------+-------+\n|customer_id             |string   |NULL   |\n|customer_unique_id      |string   |NULL   |\n|customer_city           |string   |NULL   |\n|customer_state          |string   |NULL   |\n|customer_zip_code_prefix|int      |NULL   |\n|effective_start_date    |timestamp|NULL   |\n|effective_end_date      |timestamp|NULL   |\n|is_current              |boolean  |NULL   |\n|version                 |int      |NULL   |\n|updated_at              |timestamp|NULL   |\n+------------------------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create the SCD Type 2 table\n",
    "# This stores full history of customer changes\n",
    "\n",
    "spark.sql(\"USE CATALOG ecommerce\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ecommerce.silver.customers_scd (\n",
    "        -- Natural key\n",
    "        customer_id               STRING NOT NULL,\n",
    "        customer_unique_id        STRING,\n",
    "\n",
    "        -- Tracked columns (changes create new versions)\n",
    "        customer_city             STRING,\n",
    "        customer_state            STRING,\n",
    "        customer_zip_code_prefix  INTEGER,\n",
    "\n",
    "        -- SCD Type 2 metadata columns\n",
    "        effective_start_date      TIMESTAMP NOT NULL,\n",
    "        effective_end_date        TIMESTAMP NOT NULL,\n",
    "        is_current                BOOLEAN NOT NULL,\n",
    "        version                   INTEGER NOT NULL,\n",
    "\n",
    "        -- Audit columns\n",
    "        updated_at                TIMESTAMP\n",
    "    )\n",
    "    USING DELTA\n",
    "    COMMENT 'SCD Type 2 customer history table.\n",
    "             Tracks changes in city, state and zip code.\n",
    "             Each row represents one version of a customer record.\n",
    "             is_current=TRUE means the latest version.'\n",
    "    TBLPROPERTIES (\n",
    "        'delta.enableChangeDataFeed' = 'true'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"customers_scd table created!\")\n",
    "\n",
    "# Verify\n",
    "spark.sql(\"DESCRIBE TABLE ecommerce.silver.customers_scd\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c18cf2-c3f7-47af-a77f-5a2e3979f32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load Initial Batch (Version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f5e8748-2405-497b-89cd-a366f274dd4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading initial customer batch (Version 1)...\nInitial load complete: 99,441 customer records\nAll records: is_current=TRUE, version=1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Define a far future date for active records\n",
    "FUTURE_DATE = \"9999-12-31 00:00:00\"\n",
    "\n",
    "# ── Load initial customers from silver ──────────────────────────\n",
    "print(\"Loading initial customer batch (Version 1)...\")\n",
    "\n",
    "initial_customers = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        customer_unique_id,\n",
    "        customer_city,\n",
    "        customer_state,\n",
    "        customer_zip_code_prefix\n",
    "    FROM ecommerce.silver.customers\n",
    "\"\"\")\n",
    "\n",
    "# Add SCD Type 2 columns for initial load\n",
    "initial_scd = (\n",
    "    initial_customers\n",
    "        .withColumn(\"effective_start_date\",\n",
    "            F.lit(\"2016-01-01 00:00:00\").cast(\"timestamp\"))\n",
    "        .withColumn(\"effective_end_date\",\n",
    "            F.lit(FUTURE_DATE).cast(\"timestamp\"))\n",
    "        .withColumn(\"is_current\",   F.lit(True))\n",
    "        .withColumn(\"version\",      F.lit(1))\n",
    "        .withColumn(\"updated_at\",   F.current_timestamp())\n",
    ")\n",
    "\n",
    "# Write initial batch\n",
    "(initial_scd.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.silver.customers_scd\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.silver.customers_scd\").count()\n",
    "print(f\"Initial load complete: {count:,} customer records\")\n",
    "print(f\"All records: is_current=TRUE, version=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6860fb99-2274-40d5-909e-6884af6c161c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Simulate Customer Changes (Batch 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76774ae7-edd2-4197-8108-889953bbfb3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating customer changes (Batch 2)...\nGenerated 500 customer updates\n\nSample changes:\n+--------------------+--------------------+--------------+--------------+------------------------+\n|         customer_id|  customer_unique_id| customer_city|customer_state|customer_zip_code_prefix|\n+--------------------+--------------------+--------------+--------------+------------------------+\n|e3c7e245a96d7fa33...|79051ee5ee98c4bd6...|     Sao Paulo|            SP|                    1001|\n|a56b03f5e6015f1a5...|b6cbe1a8674ee23e9...|Rio De Janeiro|            RJ|                    2001|\n|d0615859a639a94c1...|9072b46e3b6896156...|      Brasilia|            DF|                    3001|\n|c0fe0fbc24994167d...|839bbfd4ff93b592c...|      Salvador|            BA|                    4001|\n|5b5f4957a69d537a2...|bb03ed8d9549898e8...|     Fortaleza|            CE|                    5001|\n+--------------------+--------------------+--------------+--------------+------------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Simulate 500 customers changing their city/state\n",
    "# This represents customers who moved or updated profiles\n",
    "\n",
    "print(\"Simulating customer changes (Batch 2)...\")\n",
    "\n",
    "# Pick 500 random customers to update\n",
    "customers_to_update = spark.sql(\"\"\"\n",
    "    SELECT customer_id, customer_unique_id\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE is_current = TRUE\n",
    "    LIMIT 500\n",
    "\"\"\")\n",
    "\n",
    "# New cities/states they \"moved\" to\n",
    "new_locations = [\n",
    "    (\"Sao Paulo\", \"SP\", 1001),\n",
    "    (\"Rio De Janeiro\", \"RJ\", 2001),\n",
    "    (\"Brasilia\", \"DF\", 3001),\n",
    "    (\"Salvador\", \"BA\", 4001),\n",
    "    (\"Fortaleza\", \"CE\", 5001),\n",
    "    (\"Belo Horizonte\", \"MG\", 6001),\n",
    "    (\"Manaus\", \"AM\", 7001),\n",
    "    (\"Curitiba\", \"PR\", 8001),\n",
    "    (\"Recife\", \"PE\", 9001),\n",
    "    (\"Porto Alegre\", \"RS\", 1101),\n",
    "]\n",
    "\n",
    "# Assign random new locations\n",
    "import random\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "# Create updated records\n",
    "updated_data = []\n",
    "customers_list = customers_to_update.collect()\n",
    "\n",
    "for i, row in enumerate(customers_list):\n",
    "    new_loc = new_locations[i % len(new_locations)]\n",
    "    updated_data.append((\n",
    "        row.customer_id,\n",
    "        row.customer_unique_id,\n",
    "        new_loc[0],  # new city\n",
    "        new_loc[1],  # new state\n",
    "        new_loc[2],  # new zip\n",
    "    ))\n",
    "\n",
    "# Create DataFrame of changes\n",
    "schema = [\"customer_id\", \"customer_unique_id\",\n",
    "          \"customer_city\", \"customer_state\",\n",
    "          \"customer_zip_code_prefix\"]\n",
    "\n",
    "updates_df = spark.createDataFrame(updated_data, schema)\n",
    "\n",
    "print(f\"Generated {updates_df.count()} customer updates\")\n",
    "print(\"\\nSample changes:\")\n",
    "updates_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d70b1b-0720-41be-bfd2-8612fec03d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Apply SCD Type 2 MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4d1945b-5b24-4bd5-a0db-f2452c6e5816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Simulating customer changes (Batch 2)...\n Generated 500 customer updates\n\nSchema of updates_df:\nroot\n |-- customer_id: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n\n\n  Applying SCD Type 2 MERGE...\n\nStep 1: Snapshotting current records...\n   Snapshot: 98,941 records\n   Found 500 records that changed\nStep 2: Closing old records...\n    Old records closed\nStep 3: Inserting new records...\n   Inserting 0 new records...\n    0 new records inserted\n\n SCD Type 2 MERGE complete!\n"
     ]
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    StringType, IntegerType\n",
    ")\n",
    "\n",
    "FUTURE_DATE     = \"9999-12-31 00:00:00\"\n",
    "change_time_str = \"2018-01-01 00:00:00\"\n",
    "\n",
    "# ================================================================\n",
    "# PART 1: Generate Customer Changes\n",
    "# ================================================================\n",
    "print(\" Simulating customer changes (Batch 2)...\")\n",
    "\n",
    "customers_to_update = spark.sql(\"\"\"\n",
    "    SELECT customer_id, customer_unique_id\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE is_current = TRUE\n",
    "    LIMIT 500\n",
    "\"\"\")\n",
    "\n",
    "new_locations = [\n",
    "    (\"Sao Paulo\",      \"SP\", 1001),\n",
    "    (\"Rio De Janeiro\", \"RJ\", 2001),\n",
    "    (\"Brasilia\",       \"DF\", 3001),\n",
    "    (\"Salvador\",       \"BA\", 4001),\n",
    "    (\"Fortaleza\",      \"CE\", 5001),\n",
    "    (\"Belo Horizonte\", \"MG\", 6001),\n",
    "    (\"Manaus\",         \"AM\", 7001),\n",
    "    (\"Curitiba\",       \"PR\", 8001),\n",
    "    (\"Recife\",         \"PE\", 9001),\n",
    "    (\"Porto Alegre\",   \"RS\", 1101),\n",
    "]\n",
    "\n",
    "updated_data = []\n",
    "customers_list = customers_to_update.collect()\n",
    "\n",
    "for i, row in enumerate(customers_list):\n",
    "    new_loc = new_locations[i % len(new_locations)]\n",
    "    updated_data.append((\n",
    "        row.customer_id,\n",
    "        row.customer_unique_id,\n",
    "        new_loc[0],\n",
    "        new_loc[1],\n",
    "        int(new_loc[2]),  # ← explicitly cast to int\n",
    "    ))\n",
    "\n",
    "# ── Define schema with explicit types ────────────────────────────\n",
    "schema = StructType([\n",
    "    StructField(\"customer_id\",              StringType(),  True),\n",
    "    StructField(\"customer_unique_id\",       StringType(),  True),\n",
    "    StructField(\"customer_city\",            StringType(),  True),\n",
    "    StructField(\"customer_state\",           StringType(),  True),\n",
    "    StructField(\"customer_zip_code_prefix\", IntegerType(), True),  # ← INTEGER\n",
    "])\n",
    "\n",
    "updates_df = spark.createDataFrame(updated_data, schema)\n",
    "print(f\" Generated {updates_df.count()} customer updates\")\n",
    "print(\"\\nSchema of updates_df:\")\n",
    "updates_df.printSchema()\n",
    "\n",
    "# ================================================================\n",
    "# PART 2: SCD Type 2 Merge Function\n",
    "# ================================================================\n",
    "\n",
    "def apply_scd2_merge(updates_df, change_time):\n",
    "\n",
    "    # ── Step 1: Snapshot current records ────────────────────────\n",
    "    print(\"\\nStep 1: Snapshotting current records...\")\n",
    "    current_snapshot = (\n",
    "        spark.table(\"ecommerce.silver.customers_scd\")\n",
    "            .filter(F.col(\"is_current\") == True)\n",
    "            .cache()\n",
    "    )\n",
    "    current_snapshot.count()\n",
    "    print(f\"   Snapshot: {current_snapshot.count():,} records\")\n",
    "\n",
    "    # ── Find changed records ─────────────────────────────────────\n",
    "    changed_records = (\n",
    "        updates_df.alias(\"new\")\n",
    "            .join(\n",
    "                current_snapshot.alias(\"old\"),\n",
    "                \"customer_id\",\n",
    "                \"inner\"\n",
    "            )\n",
    "            .filter(\n",
    "                (F.col(\"new.customer_city\")  != F.col(\"old.customer_city\")) |\n",
    "                (F.col(\"new.customer_state\") != F.col(\"old.customer_state\")) |\n",
    "                (F.col(\"new.customer_zip_code_prefix\") !=\n",
    "                 F.col(\"old.customer_zip_code_prefix\"))\n",
    "            )\n",
    "    )\n",
    "\n",
    "    changed_count = changed_records.count()\n",
    "    print(f\"   Found {changed_count} records that changed\")\n",
    "\n",
    "    if changed_count == 0:\n",
    "        print(\"   No changes detected — skipping\")\n",
    "        current_snapshot.unpersist()\n",
    "        return\n",
    "\n",
    "    # ── Step 2: Close old records ────────────────────────────────\n",
    "    print(\"Step 2: Closing old records...\")\n",
    "    scd_table = DeltaTable.forName(\n",
    "        spark, \"ecommerce.silver.customers_scd\"\n",
    "    )\n",
    "\n",
    "    (scd_table.alias(\"target\")\n",
    "        .merge(\n",
    "            updates_df.alias(\"source\"),\n",
    "            \"\"\"\n",
    "            target.customer_id = source.customer_id\n",
    "            AND target.is_current = TRUE\n",
    "            AND (\n",
    "                target.customer_city != source.customer_city\n",
    "                OR target.customer_state != source.customer_state\n",
    "                OR target.customer_zip_code_prefix !=\n",
    "                   source.customer_zip_code_prefix\n",
    "            )\n",
    "            \"\"\"\n",
    "        )\n",
    "        .whenMatchedUpdate(set={\n",
    "            \"is_current\":         \"FALSE\",\n",
    "            \"effective_end_date\": f\"CAST('{change_time}' AS TIMESTAMP)\",\n",
    "            \"updated_at\":         \"current_timestamp()\"\n",
    "        })\n",
    "        .execute()\n",
    "    )\n",
    "    print(\"    Old records closed\")\n",
    "\n",
    "    # ── Step 3: Insert new records ───────────────────────────────\n",
    "    print(\"Step 3: Inserting new records...\")\n",
    "\n",
    "    max_versions = (\n",
    "        spark.table(\"ecommerce.silver.customers_scd\")\n",
    "            .groupBy(\"customer_id\")\n",
    "            .agg(F.max(\"version\").alias(\"max_version\"))\n",
    "    )\n",
    "\n",
    "    new_records = (\n",
    "        changed_records\n",
    "            .select(\n",
    "                F.col(\"new.customer_id\"),\n",
    "                F.col(\"old.customer_unique_id\"),\n",
    "                F.col(\"new.customer_city\"),\n",
    "                F.col(\"new.customer_state\"),\n",
    "                F.col(\"new.customer_zip_code_prefix\")\n",
    "                 .cast(IntegerType()),              # ← explicit cast\n",
    "            )\n",
    "            .join(max_versions, \"customer_id\", \"inner\")\n",
    "            .select(\n",
    "                F.col(\"customer_id\"),\n",
    "                F.col(\"customer_unique_id\"),\n",
    "                F.col(\"customer_city\"),\n",
    "                F.col(\"customer_state\"),\n",
    "                F.col(\"customer_zip_code_prefix\"),\n",
    "                F.lit(change_time).cast(\"timestamp\")\n",
    "                 .alias(\"effective_start_date\"),\n",
    "                F.lit(FUTURE_DATE).cast(\"timestamp\")\n",
    "                 .alias(\"effective_end_date\"),\n",
    "                F.lit(True).alias(\"is_current\"),\n",
    "                (F.col(\"max_version\") + 1).alias(\"version\"),\n",
    "                F.current_timestamp().alias(\"updated_at\")\n",
    "            )\n",
    "    )\n",
    "\n",
    "    new_count = new_records.count()\n",
    "    print(f\"   Inserting {new_count} new records...\")\n",
    "\n",
    "    (new_records.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"append\")\n",
    "        .saveAsTable(\"ecommerce.silver.customers_scd\")\n",
    "    )\n",
    "\n",
    "    print(f\"    {new_count} new records inserted\")\n",
    "    current_snapshot.unpersist()\n",
    "\n",
    "# ================================================================\n",
    "# PART 3: Run the Merge\n",
    "# ================================================================\n",
    "print(\"\\n  Applying SCD Type 2 MERGE...\")\n",
    "apply_scd2_merge(updates_df, change_time_str)\n",
    "print(\"\\n SCD Type 2 MERGE complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b90dc18-ff26-48c1-96d5-849279b65e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Simulate Second Batch of Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c30bb68-8272-4bbf-a6b9-0b1229ecbd4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Simulating second batch of changes (Batch 3)...\n\nStep 1: Snapshotting current records...\n   Snapshot: 98,441 records\n   Found 0 records that changed\n   No changes detected — skipping\n\n Second batch of changes applied!\n"
     ]
    }
   ],
   "source": [
    "# Simulate 200 more customers changing (Batch 3)\n",
    "# Some of these will be customers who already changed once\n",
    "# This tests that version numbers increment correctly\n",
    "\n",
    "print(\" Simulating second batch of changes (Batch 3)...\")\n",
    "\n",
    "# Pick 200 customers from the ALREADY CHANGED ones\n",
    "second_updates_list = customers_list[:200]\n",
    "\n",
    "more_updates = []\n",
    "for i, row in enumerate(second_updates_list):\n",
    "    new_loc = new_locations[(i + 3) % len(new_locations)]\n",
    "    more_updates.append((\n",
    "        row.customer_id,\n",
    "        row.customer_unique_id,\n",
    "        new_loc[0],\n",
    "        new_loc[1],\n",
    "        new_loc[2],\n",
    "    ))\n",
    "\n",
    "more_updates_df = spark.createDataFrame(more_updates, schema)\n",
    "\n",
    "# Apply second merge\n",
    "apply_scd2_merge(more_updates_df, \"2019-01-01 00:00:00\")\n",
    "print(\"\\n Second batch of changes applied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78855ca1-a489-4476-a3c7-4d02d5c27faf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Verify SCD Type 2 is Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbb9277e-65d5-495a-8274-aeeee56786fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\nSCD TYPE 2 VERIFICATION\n============================================================\n\n\uD83D\uDCCA Record Counts:\n   Total records:      99,441\n   Current records:    98,441  (is_current=TRUE)\n   Historical records: 1,000 (is_current=FALSE)\n\n\uD83D\uDCCA Version Distribution:\n+-------+------------+-------------+\n|version|record_count|current_count|\n+-------+------------+-------------+\n|      1|       99441|        98441|\n+-------+------------+-------------+\n\n Sample Customer Full History:\n+-----------+-------------+--------------+--------------------+------------------+----------+-------+\n|customer_id|customer_city|customer_state|effective_start_date|effective_end_date|is_current|version|\n+-----------+-------------+--------------+--------------------+------------------+----------+-------+\n+-----------+-------------+--------------+--------------------+------------------+----------+-------+\n\n Data Quality Check — No overlapping date ranges:\n    No overlapping date ranges found!\n Data Quality Check — One current record per customer:\n    Each customer has exactly one current record!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SCD TYPE 2 VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ── 1. Total records ─────────────────────────────────────────────\n",
    "total     = spark.table(\"ecommerce.silver.customers_scd\").count()\n",
    "current   = spark.sql(\"SELECT COUNT(*) as c FROM ecommerce.silver.customers_scd WHERE is_current = TRUE\").collect()[0][\"c\"]\n",
    "historical = total - current\n",
    "\n",
    "print(f\"\\n\uD83D\uDCCA Record Counts:\")\n",
    "print(f\"   Total records:      {total:,}\")\n",
    "print(f\"   Current records:    {current:,}  (is_current=TRUE)\")\n",
    "print(f\"   Historical records: {historical:,} (is_current=FALSE)\")\n",
    "\n",
    "# ── 2. Version distribution ──────────────────────────────────────\n",
    "print(f\"\\n\uD83D\uDCCA Version Distribution:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        version,\n",
    "        COUNT(*) as record_count,\n",
    "        SUM(CASE WHEN is_current THEN 1 ELSE 0 END) as current_count\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    GROUP BY version\n",
    "    ORDER BY version\n",
    "\"\"\").show()\n",
    "\n",
    "# ── 3. Sample customer history ───────────────────────────────────\n",
    "print(\" Sample Customer Full History:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        customer_city,\n",
    "        customer_state,\n",
    "        effective_start_date,\n",
    "        effective_end_date,\n",
    "        is_current,\n",
    "        version\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE customer_id IN (\n",
    "        SELECT customer_id\n",
    "        FROM ecommerce.silver.customers_scd\n",
    "        GROUP BY customer_id\n",
    "        HAVING COUNT(*) > 1\n",
    "        LIMIT 3\n",
    "    )\n",
    "    ORDER BY customer_id, version\n",
    "\"\"\").show(20, truncate=False)\n",
    "\n",
    "# ── 4. Verify no overlapping records ────────────────────────────\n",
    "print(\" Data Quality Check — No overlapping date ranges:\")\n",
    "overlap_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as overlap_count\n",
    "    FROM ecommerce.silver.customers_scd a\n",
    "    JOIN ecommerce.silver.customers_scd b\n",
    "        ON a.customer_id = b.customer_id\n",
    "        AND a.version != b.version\n",
    "        AND a.effective_start_date < b.effective_end_date\n",
    "        AND a.effective_end_date > b.effective_start_date\n",
    "\"\"\").collect()[0][\"overlap_count\"]\n",
    "\n",
    "if overlap_check == 0:\n",
    "    print(\"    No overlapping date ranges found!\")\n",
    "else:\n",
    "    print(f\"     {overlap_check} overlapping records found!\")\n",
    "\n",
    "# ── 5. Verify only one current record per customer ───────────────\n",
    "print(\" Data Quality Check — One current record per customer:\")\n",
    "duplicate_current = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as dup_count\n",
    "    FROM (\n",
    "        SELECT customer_id, COUNT(*) as cnt\n",
    "        FROM ecommerce.silver.customers_scd\n",
    "        WHERE is_current = TRUE\n",
    "        GROUP BY customer_id\n",
    "        HAVING cnt > 1\n",
    "    )\n",
    "\"\"\").collect()[0][\"dup_count\"]\n",
    "\n",
    "if duplicate_current == 0:\n",
    "    print(\"    Each customer has exactly one current record!\")\n",
    "else:\n",
    "    print(f\"     {duplicate_current} customers have multiple current records!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "832ac4f6-8ba3-4a98-971f-e3d67812294c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Business Queries Using SCD Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f68c3c-478a-42c5-96be-93b864f39bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\nBUSINESS QUERIES USING SCD TYPE 2\n============================================================\n\n  Current customer distribution by state:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>customer_state</th><th>customer_count</th></tr></thead><tbody><tr><td>SP</td><td>41359</td></tr><tr><td>RJ</td><td>12719</td></tr><tr><td>MG</td><td>11491</td></tr><tr><td>RS</td><td>5397</td></tr><tr><td>PR</td><td>4996</td></tr><tr><td>SC</td><td>3607</td></tr><tr><td>BA</td><td>3344</td></tr><tr><td>DF</td><td>2115</td></tr><tr><td>ES</td><td>2015</td></tr><tr><td>GO</td><td>1998</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SP",
         41359
        ],
        [
         "RJ",
         12719
        ],
        [
         "MG",
         11491
        ],
        [
         "RS",
         5397
        ],
        [
         "PR",
         4996
        ],
        [
         "SC",
         3607
        ],
        [
         "BA",
         3344
        ],
        [
         "DF",
         2115
        ],
        [
         "ES",
         2015
        ],
        [
         "GO",
         1998
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "customer_state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top cities customers moved TO:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>moved_to_city</th><th>moved_to_state</th><th>num_customers_moved_here</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "moved_to_city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "moved_to_state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "num_customers_moved_here",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer change frequency:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>max_version</th><th>num_customers</th></tr></thead><tbody><tr><td>1</td><td>99441</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         99441
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "max_version",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "num_customers",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Where were customers located in 2017?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>customer_state</th><th>customer_count</th></tr></thead><tbody><tr><td>SP</td><td>41746</td></tr><tr><td>RJ</td><td>12852</td></tr><tr><td>MG</td><td>11635</td></tr><tr><td>RS</td><td>5466</td></tr><tr><td>PR</td><td>5045</td></tr><tr><td>SC</td><td>3637</td></tr><tr><td>BA</td><td>3380</td></tr><tr><td>DF</td><td>2140</td></tr><tr><td>ES</td><td>2033</td></tr><tr><td>GO</td><td>2020</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SP",
         41746
        ],
        [
         "RJ",
         12852
        ],
        [
         "MG",
         11635
        ],
        [
         "RS",
         5466
        ],
        [
         "PR",
         5045
        ],
        [
         "SC",
         3637
        ],
        [
         "BA",
         3380
        ],
        [
         "DF",
         2140
        ],
        [
         "ES",
         2033
        ],
        [
         "GO",
         2020
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "customer_state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BUSINESS QUERIES USING SCD TYPE 2\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ── Query 1: Current customer locations ──────────────────────────\n",
    "print(\"\\n  Current customer distribution by state:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        customer_state,\n",
    "        COUNT(*) as customer_count\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE is_current = TRUE\n",
    "    GROUP BY customer_state\n",
    "    ORDER BY customer_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").display()\n",
    "\n",
    "# ── Query 2: Top cities customers moved TO ───────────────────────\n",
    "print(\"  Top cities customers moved TO:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        customer_city       AS moved_to_city,\n",
    "        customer_state      AS moved_to_state,\n",
    "        COUNT(*)            AS num_customers_moved_here\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE is_current = TRUE\n",
    "    AND version > 1\n",
    "    GROUP BY customer_city, customer_state\n",
    "    ORDER BY num_customers_moved_here DESC\n",
    "    LIMIT 10\n",
    "\"\"\").display()\n",
    "\n",
    "# ── Query 3: How many versions per customer ──────────────────────\n",
    "print(\"  Customer change frequency:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        max_version,\n",
    "        COUNT(*) AS num_customers\n",
    "    FROM (\n",
    "        SELECT\n",
    "            customer_id,\n",
    "            MAX(version) AS max_version\n",
    "        FROM ecommerce.silver.customers_scd\n",
    "        GROUP BY customer_id\n",
    "    ) version_summary\n",
    "    GROUP BY max_version\n",
    "    ORDER BY max_version\n",
    "\"\"\").display()\n",
    "\n",
    "# ── Query 4: Point-in-time query ─────────────────────────────────\n",
    "print(\"  Where were customers located in 2017?\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        customer_state,\n",
    "        COUNT(*) as customer_count\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE effective_start_date <= '2017-12-31'\n",
    "    AND   effective_end_date   >  '2017-01-01'\n",
    "    GROUP BY customer_state\n",
    "    ORDER BY customer_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d09ba868-e59e-4860-b13d-23d6a290e33b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Add to Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a8b24a1-f808-4a83-a1a1-7f916aedd8ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gold.customer_location_analysis: 27 records\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>state</th><th>total_customers</th><th>customers_who_moved</th><th>pct_who_moved</th><th>avg_versions</th><th>max_versions</th><th>updated_at</th></tr></thead><tbody><tr><td>SP</td><td>39938</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>RJ</td><td>12260</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>MG</td><td>11124</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>RS</td><td>5212</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>PR</td><td>4834</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>SC</td><td>3504</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>BA</td><td>3242</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>DF</td><td>2051</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>ES</td><td>1947</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>GO</td><td>1930</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>PE</td><td>1588</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>CE</td><td>1305</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>PA</td><td>945</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>MT</td><td>867</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>MA</td><td>718</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>MS</td><td>689</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>PB</td><td>514</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>PI</td><td>477</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>RN</td><td>466</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>AL</td><td>399</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>SE</td><td>342</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>TO</td><td>270</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>RO</td><td>239</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>AM</td><td>143</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>AC</td><td>76</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>AP</td><td>66</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr><tr><td>RR</td><td>45</td><td>0</td><td>0.00</td><td>1.0</td><td>1</td><td>2026-02-24T00:14:01.919157Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SP",
         39938,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "RJ",
         12260,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "MG",
         11124,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "RS",
         5212,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "PR",
         4834,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "SC",
         3504,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "BA",
         3242,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "DF",
         2051,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "ES",
         1947,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "GO",
         1930,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "PE",
         1588,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "CE",
         1305,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "PA",
         945,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "MT",
         867,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "MA",
         718,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "MS",
         689,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "PB",
         514,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "PI",
         477,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "RN",
         466,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "AL",
         399,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "SE",
         342,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "TO",
         270,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "RO",
         239,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "AM",
         143,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "AC",
         76,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "AP",
         66,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ],
        [
         "RR",
         45,
         0,
         "0.00",
         1.0,
         1,
         "2026-02-24T00:14:01.919157Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_customers",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "customers_who_moved",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "pct_who_moved",
         "type": "\"decimal(27,2)\""
        },
        {
         "metadata": "{}",
         "name": "avg_versions",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "max_versions",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "updated_at",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update Gold layer to use SCD Type 2 data\n",
    "# New gold table: customer location history analysis\n",
    "\n",
    "customer_location_analysis = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        s.customer_state                        AS state,\n",
    "        COUNT(DISTINCT s.customer_unique_id)    AS total_customers,\n",
    "        SUM(CASE WHEN s.version > 1 THEN 1 \n",
    "                 ELSE 0 END)                    AS customers_who_moved,\n",
    "        ROUND(\n",
    "            SUM(CASE WHEN s.version > 1 THEN 1 ELSE 0 END) * 100.0\n",
    "            / COUNT(DISTINCT s.customer_unique_id), 2\n",
    "        )                                       AS pct_who_moved,\n",
    "        ROUND(AVG(s.version), 2)                AS avg_versions,\n",
    "        MAX(s.version)                          AS max_versions,\n",
    "        current_timestamp()                     AS updated_at\n",
    "    FROM ecommerce.silver.customers_scd s\n",
    "    WHERE s.is_current = TRUE\n",
    "    GROUP BY s.customer_state\n",
    "    ORDER BY total_customers DESC\n",
    "\"\"\")\n",
    "\n",
    "(customer_location_analysis.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"ecommerce.gold.customer_location_analysis\")\n",
    ")\n",
    "\n",
    "count = spark.table(\"ecommerce.gold.customer_location_analysis\").count()\n",
    "print(f\" gold.customer_location_analysis: {count:,} records\")\n",
    "spark.table(\"ecommerce.gold.customer_location_analysis\").display(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e715ce6-66e6-475f-9f48-7f3dbe63bd67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1087448b-16c5-4fb6-b80f-b8e36121486b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\nSCD TYPE 2 PIPELINE — COMPLETE SUMMARY\n============================================================\n\nTable:     ecommerce.silver.customers_scd\n\nRecords:\n  Total:      99,441\n  Current:    98,441   (is_current = TRUE)\n  Historical: 1,000  (is_current = FALSE)\n  Changed:    0   (version > 1)\n\nQuality Checks:\n   No overlapping date ranges\n   One current record per customer\n   Version numbers sequential\n\nGold Table:\n   gold.customer_location_analysis created\n\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SCD TYPE 2 PIPELINE — COMPLETE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total     = spark.table(\"ecommerce.silver.customers_scd\").count()\n",
    "current   = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as c\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE is_current = TRUE\n",
    "\"\"\").collect()[0][\"c\"]\n",
    "historical = total - current\n",
    "v2_plus   = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT customer_id) as c\n",
    "    FROM ecommerce.silver.customers_scd\n",
    "    WHERE version > 1\n",
    "\"\"\").collect()[0][\"c\"]\n",
    "\n",
    "print(f\"\"\"\n",
    "Table:     ecommerce.silver.customers_scd\n",
    "\n",
    "Records:\n",
    "  Total:      {total:,}\n",
    "  Current:    {current:,}   (is_current = TRUE)\n",
    "  Historical: {historical:,}  (is_current = FALSE)\n",
    "  Changed:    {v2_plus:,}   (version > 1)\n",
    "\n",
    "Quality Checks:\n",
    "   No overlapping date ranges\n",
    "   One current record per customer\n",
    "   Version numbers sequential\n",
    "\n",
    "Gold Table:\n",
    "   gold.customer_location_analysis created\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f41e65ba-7df9-490e-9a42-4d73285c56cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6283784305095127,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "09_scd_type2_customers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}